<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Toyozaki Xaver Tomihiro on Toyozaki Xaver Tomihiro</title>
    <link>http://toyozaki.me/index.xml</link>
    <description>Recent content in Toyozaki Xaver Tomihiro on Toyozaki Xaver Tomihiro</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Toyozaki Xaver Tomihiro [All right reserved.]</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>AmbientLetter</title>
      <link>http://toyozaki.me/project/AmbientLetter/</link>
      <pubDate>Fri, 29 Dec 2017 17:00:09 +0900</pubDate>
      
      <guid>http://toyozaki.me/project/AmbientLetter/</guid>
      <description>

&lt;h3 id=&#34;ambientletter-わからないスペルをこっそり知るための文字認識及び文字提示手法&#34;&gt;AmbientLetter：わからないスペルをこっそり知るための文字認識及び文字提示手法&lt;/h3&gt;

&lt;p&gt;という題目で、インタラクティブシステムとソフトウェアに関するワークショップ（WISS）でデモ発表をしました。&lt;br /&gt;
  　&lt;/p&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;コンピュータ上では入力した文字のスペルミスの指摘や修正が可能である．しかし，会議や
講義などの場面で鉛筆やチョーク等を利用する場合にはそのような機能を利用できない．そこで，本
研究では，直筆が必要な場面において，忘れてしまったスペルをシームレスにこっそりとユーザ本人
にのみ提示するシステムである AmbientLetter を提案する．本システムはペンに装着した 9 軸加速度
センサを用いた文字認識部，執筆内容から次の文字を予測する提示文字予測部，環境にカモフラージ
ュし次の文字を提示する文字提示部の 3 つの要素で構成される．文字認識部のシステム評価の結果，
86.5%で筆記された文字を正しく認識できた．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Traxionの追実装＋パワーの増幅信号</title>
      <link>http://toyozaki.me/post/AmplicateTraxionPower/</link>
      <pubDate>Wed, 27 Sep 2017 11:59:17 +0900</pubDate>
      
      <guid>http://toyozaki.me/post/AmplicateTraxionPower/</guid>
      <description>&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;traxionの追実装&#34;&gt;Traxionの追実装&lt;/h3&gt;

&lt;p&gt;Traxionの追実装を行いました。これだけでは別に珍しくないのでさらっと書きます。&lt;/p&gt;

&lt;p&gt;Traxionを追実装するにあたっては、アルプス社のHaptic Reactorを利用します。
これはswitchのコントローラーに入っているので取り出します。
左の白いクッションの様なものがついているものがHaptic Reactorです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://toyozaki.me/img/post_2017-09-27/P_20170511_150220.jpg&#34; alt=&#34;Traxion&#34; /&gt;
&lt;img src=&#34;http://toyozaki.me/img/post_2017-09-27/P_20170511_150714.jpg&#34; alt=&#34;Traxion&#34; /&gt;&lt;/p&gt;

&lt;p&gt;これをアンプに繋げて、矩形波を流すだけです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://toyozaki.me/img/post_2017-09-27/DSC_0097.JPG&#34; alt=&#34;Traxion&#34; /&gt;&lt;/p&gt;

&lt;p&gt;一秒おきに力の向きを変えて矩形波を出力。（デューティー比、2:6と6:2を交互に流す。）
&lt;img src=&#34;http://toyozaki.me/img/post_2017-09-27/traxion.gif&#34; alt=&#34;Traxion&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;地味にわかりづらい&#34;&gt;地味にわかりづらい&lt;/h3&gt;

&lt;p&gt;やってみるとわかりますが、Traxionの力覚はだれもがわかるというほど強くはないです。
もってみると、どっちの向きに力が働いているか集中してみないとわからなかったりします。
左右に動かしながら持ってみると感じやすいとかはありますが、それでも微妙です。
&lt;br&gt;&lt;/p&gt;

&lt;h1 id=&#34;パワーの増幅&#34;&gt;パワーの増幅&lt;/h1&gt;

&lt;p&gt;特定の信号をながすことで振動子を用いた仮想力覚が生じます。
もともとのTraxionの論文ではデューティ比2:6の信号を125Hzでながすとありますが、今回使っている振動子はそれとは異なるため、少し変わります。
アルプス電気のサイトによると、今回使う振動子は160Hzで強く振動するらしいです。
&lt;img src=&#34;http://toyozaki.me/img/post_2017-09-27/figure_s1.png&#34; alt=&#34;Traxion&#34; /&gt;&lt;/p&gt;

&lt;p&gt;この信号を以下のようにすることで、仮想力覚のパワーが増加しました。あくまでも個人の感覚で、実験はしていないですが。
&lt;img src=&#34;http://toyozaki.me/img/post_2017-09-27/figure_1.png&#34; alt=&#34;Traxion&#34; /&gt;
上の画像とこの画像の意味合いの符合がとれていないので少しわかりづらいですが、
この画像の左側と右側はTraxionの力の向きが反対であることを意味します。&lt;br&gt;
同様に160Hzです。&lt;br&gt;
普通の方が6:2に対して1つのパルスの右側をsin派にします。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>H.265/HEVC &#43; Deep Learning</title>
      <link>http://toyozaki.me/project/H.265:HEVC&#43;Deep-Learning/</link>
      <pubDate>Sun, 09 Apr 2017 16:32:20 +0900</pubDate>
      
      <guid>http://toyozaki.me/project/H.265:HEVC&#43;Deep-Learning/</guid>
      <description>

&lt;h3 id=&#34;深層学習を用いたhevcイントラ予測モード決定手法の検討&#34;&gt;深層学習を用いたHEVCイントラ予測モード決定手法の検討&lt;/h3&gt;

&lt;p&gt;という題目で電子情報通信学会の総合大会2017（名城大学）で&lt;a href=&#34;http://www.gakkai-web.net/gakkai/ieice/G_2017/Settings/ab/d_11_056.html&#34; target=&#34;_blank&#34;&gt;発表&lt;/a&gt;してきました。
同時に卒業研究でもあります。&lt;/p&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;動画像符号化規格HEVC/H.265の参照ソフトウェアHEVC Test Modelでは，RD最適化を行うことで最適な予測モードを決定している．しかし，RD最適化は計算量が多くエンコードには時間がかかる．
そこで，35モードあるイントラ予測モード決定に深層学習を用いることを検討した。
本稿では，CNNの入力に当該PUのみを使用する手法，当該PUと隣接画素を入力とした手法，予測モードをランダムに決定した手法においてBD-Rateによる比較を行った．
結果として，CNNを利用するイントラ予測モード決定はランダムに決定する手法と比較し，有意性があることを確かめた．
また、隣接画素を含んだ手法は含んでいない手法より符号化効率が高いことがわかった．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ホームページを作成しました。</title>
      <link>http://toyozaki.me/post/my-first-article/</link>
      <pubDate>Sun, 09 Apr 2017 15:54:39 +0900</pubDate>
      
      <guid>http://toyozaki.me/post/my-first-article/</guid>
      <description>&lt;p&gt;
2017年3月に明治大学 総合数理学部 先端メディアサイエンス学科を卒業し、
2017年4月に明治大学大学院 先端数理科学研究科 先端メディアサイエンス専攻に進学しました。
学部では動画像符号化や画像処理の研究を行っていましたが、大学院では渡邊研究室に所属し、インタラクションの研究をしていくことになります。
そして今後は様々な作品や研究に携わることができればと思います。&lt;/p&gt;

&lt;p&gt;このホームページでもプロジェクトやポートフォリオをまとめていくサイトにするつもりです。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
